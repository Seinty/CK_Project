{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3da84f39-9082-47f2-a1ab-4fc38f3bc144",
   "metadata": {},
   "source": [
    "## Файл с предобработкой данных  \n",
    "На вход мы подаем наш датасет, а на выходе получаем отчищенный от случайных, неинформативных символов, лемматизированный, векторизованный по методу TF-IDF на униграммы\\биграммы\\триграммы и разбитый на тренировочную и тестовую выборки."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "611077e0-90b1-4862-ac28-f280c371ccec",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import re\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from nltk.corpus import wordnet\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "4e22aac3-003c-4e2f-9d23-0d7c3116b73d",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('./IMDB Dataset.csv')\n",
    "\n",
    "# Лемматизация текста\n",
    "def lemmatize_text(text):\n",
    "    return ' '.join([lemmatizer.lemmatize(word) for word in text.split()])\n",
    "\n",
    "def clean_text(\n",
    "        text : str\n",
    ")->str:\n",
    "    \"\"\"\n",
    "    Очищает текст от HTML тегов, специальных символов и приводит его к нижнему регистру.\n",
    "    Параметры:\n",
    "    text (str): Исходный текст.\n",
    "    Возвращает:\n",
    "    str: Очищенный текст.\n",
    "    \"\"\"\n",
    "    text = text.lower()\n",
    "    text = re.sub(r'<.*?>', '', text)\n",
    "    text = re.sub(r'[^A-Za-z0-9\\s]', '', text)\n",
    "    text = re.sub(r'(.)\\1{2,}', r'\\1', text)\n",
    "    text = ' '.join([word for word in text.split() if word not in stop_words])\n",
    "    text = lemmatize_text(text)\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "03aba8aa-d581-4a34-9f85-a5f8b8f68882",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\andre\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\andre\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "# Загрузка стоп-слов\n",
    "nltk.download('stopwords')\n",
    "nltk.download('wordnet')\n",
    "stop_words = set(stopwords.words('english'))\n",
    "lemmatizer = WordNetLemmatizer()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d4dd3da-250b-4702-87e0-2386438f510e",
   "metadata": {},
   "source": [
    "### Текст до отчистки"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "92210d19-80ac-4ecb-9071-24668a8c5c46",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Probably my all-time favorite movie, a story of selflessness, sacrifice and dedication to a noble cause, but it's not preachy or boring. It just never gets old, despite my having seen it some 15 or more times in the last 25 years. Paul Lukas' performance brings tears to my eyes, and Bette Davis, in one of her very few truly sympathetic roles, is a delight. The kids are, as grandma says, more like \"dressed-up midgets\" than children, but that only makes them more fun to watch. And the mother's slow awakening to what's happening in the world and under her own roof is believable and startling. If I had a dozen thumbs, they'd all be \"up\" for this movie.\n"
     ]
    }
   ],
   "source": [
    "print(data.iloc[5,0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "461ef60f-7024-4796-b797-3fda841c805d",
   "metadata": {},
   "source": [
    "### Текст после отчистки"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "095a7ae2-9720-4132-8a80-068fa53ca88a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "probably alltime favorite movie story selflessness sacrifice dedication noble cause preachy boring never get old despite seen 15 time last 25 year paul lukas performance brings tear eye bette davis one truly sympathetic role delight kid grandma say like dressedup midget child make fun watch mother slow awakening whats happening world roof believable startling dozen thumb theyd movie\n"
     ]
    }
   ],
   "source": [
    "# Отчищаем данные и бинаризуем целевой параметр\n",
    "data[\"review\"] = data['review'].apply(clean_text)\n",
    "data['sentiment'] = data['sentiment'].apply(lambda x: 1 if x == 'positive' else 0)\n",
    "print(data.iloc[5,0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "2a1b9c35-2125-447a-9a8c-222ad96ba709",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(data['review'], data['sentiment'], test_size=0.2, random_state=42)\n",
    "\n",
    "# Разделяю текст на униграммы\\биграммы\n",
    "tfidf = TfidfVectorizer(ngram_range=(1,3),max_features=8000)\n",
    "X_train_tfidf = tfidf.fit_transform(X_train).toarray()\n",
    "X_test_tfidf = tfidf.transform(X_test).toarray()\n",
    "\n",
    "train_data = {\n",
    "    'features': X_train_tfidf,\n",
    "    'labels': y_train\n",
    "}\n",
    "\n",
    "test_data = {\n",
    "    'features': X_test_tfidf,\n",
    "    'labels': y_test\n",
    "}\n",
    "\n",
    "# Сохранение тренировочных данных в pickle\n",
    "with open('./files/train_data.pkl', 'wb') as f:\n",
    "    pickle.dump(train_data, f)\n",
    "\n",
    "# Сохранение тестовых данных в pickle\n",
    "with open('./files/test_data.pkl', 'wb') as f:\n",
    "    pickle.dump(test_data, f)\n",
    "\n",
    "# Сохранение отчищенного текста в pickle\n",
    "with open('./files/Cleaned_Data.pkl', 'wb') as f:\n",
    "    pickle.dump(data, f)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "venv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
